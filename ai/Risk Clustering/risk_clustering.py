# -*- coding: utf-8 -*-
"""Risk Clustering

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14zdN4MHq5224574Bs8HMgNdJqE20EyiD
"""

df.columns.tolist()

import pandas as pd
import numpy as np

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

import pandas as pd

df = pd.read_csv("student_features_preprocessed.csv")  # use your actual filename

df.head()
df.info()

clustering_features = [
    "total_time_spent",
    "access_frequency",
    "active_days",
    "avg_quiz_score",
    "avg_assignment_score",
    "late_submission_ratio",
    "failed_courses"
]

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(df[clustering_features])

X = X_scaled

kmeans = KMeans(
    n_clusters=3,
    random_state=42,
    n_init=10
)

cluster_labels = kmeans.fit_predict(X)

df["risk_cluster"] = cluster_labels

cluster_analysis = (
    df
    .groupby("risk_cluster")[clustering_features]
    .mean()
    .round(2)
)

cluster_analysis

risk_mapping = {
    0: "Low Risk",
    1: "Medium Risk",
    2: "High Risk"
}

df["risk_level"] = df["risk_cluster"].map(risk_mapping)

silhouette_avg = silhouette_score(X, cluster_labels)
silhouette_avg

recommendations = {
    "Low Risk": "Maintain current study habits. Explore advanced materials and optional challenges.",
    "Medium Risk": "Increase consistency. Focus on weak topics and follow a structured study plan.",
    "High Risk": "Immediate intervention needed. Reduce procrastination, review fundamentals, and seek academic support."
}

df["generic_recommendation"] = df["risk_level"].map(recommendations)

print(X.shape)
print(df[clustering_features].isnull().sum())

